{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":65711,"databundleVersionId":7405009,"sourceType":"competition"},{"sourceId":5536933,"sourceType":"datasetVersion","datasetId":3191230},{"sourceId":160585923,"sourceType":"kernelVersion"}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ubaydulloasatullaev/bank-churn-binary-pgs41-autogluon?scriptVersionId=161129356\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Prepare everything","metadata":{}},{"cell_type":"code","source":"!pip install -U autogluon > /dev/null\n\n\nfrom autogluon.tabular import TabularDataset, TabularPredictor\nimport pandas as pd\nimport numpy as np\n\n\nTRAIN = '/kaggle/input/playground-series-s4e1/train.csv'\nTEST = '/kaggle/input/playground-series-s4e1/test.csv'\nORIGINAL = '/kaggle/input/bank-customer-churn-prediction/Churn_Modelling.csv'\n\n\ndf_train = pd.read_csv(TRAIN)\ndf_orig = pd.read_csv(ORIGINAL)\ndf_test = pd.read_csv(TEST)\n\n\n# Include the original dataset\ndf_train = pd.concat((df_train, df_orig), axis=0).drop(['id', 'RowNumber'], axis=1).drop_duplicates().dropna()","metadata":{"execution":{"iopub.status.busy":"2024-01-31T06:43:14.829971Z","iopub.execute_input":"2024-01-31T06:43:14.83041Z","iopub.status.idle":"2024-01-31T06:48:32.168295Z","shell.execute_reply.started":"2024-01-31T06:43:14.83036Z","shell.execute_reply":"2024-01-31T06:48:32.166268Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\naiobotocore 2.11.0 requires botocore<1.34.23,>=1.33.2, but you have botocore 1.29.165 which is incompatible.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 15.0.0 which is incompatible.\nbeatrix-jupyterlab 2023.128.151533 requires jupyterlab~=3.6.0, but you have jupyterlab 4.0.11 which is incompatible.\nconda 23.11.0 requires packaging>=23.0, but you have packaging 21.3 which is incompatible.\ngoogle-cloud-aiplatform 0.6.0a1 requires google-api-core[grpc]<2.0.0dev,>=1.22.2, but you have google-api-core 2.11.1 which is incompatible.\ngoogle-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.11.1 which is incompatible.\njupyter-events 0.9.0 requires jsonschema[format-nongpl]>=4.18.0, but you have jsonschema 4.17.3 which is incompatible.\njupyterlab 4.0.11 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.0.2 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-server 2.25.2 requires jsonschema>=4.18.0, but you have jsonschema 4.17.3 which is incompatible.\njupyterlab-server 2.25.2 requires requests>=2.31, but you have requests 2.28.2 which is incompatible.\nkaggle-environments 1.14.3 requires transformers>=4.33.1, but you have transformers 4.31.0 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nlibpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.8.1 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\npreprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.8.1 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorflowjs 4.16.0 requires packaging~=23.1, but you have packaging 21.3 which is incompatible.\ntorchaudio 2.1.2+cpu requires torch==2.1.2, but you have torch 2.0.1 which is incompatible.\ntorchtext 0.16.2+cpu requires torch==2.1.2, but you have torch 2.0.1 which is incompatible.\nxarray 2024.1.0 requires packaging>=22, but you have packaging 21.3 which is incompatible.\nydata-profiling 4.6.4 requires pydantic>=2, but you have pydantic 1.10.14 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"# Apply different preprocessing schemes","metadata":{}},{"cell_type":"code","source":"# Below is simple feature processing from https://www.kaggle.com/code/lordpatil/automl-autogluon\n\n\ndef processing1(df):\n    df['Surname_len'] = df['Surname'].apply(len)\n    df['Geography'] = df['Geography'].map({'France': 0, 'Spain': 1, 'Germany': 2})\n    df['Gender'] = (df['Gender']=='Male').astype(np.int64)\n    return df\n\ndef processing2(df):\n    cols = ['CustomerId', 'Surname', 'CreditScore', 'Geography', 'Gender', 'Age', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember','EstimatedSalary', 'Exited']\n    df = df.loc[df.groupby(cols)['Tenure'].idxmax()].drop_duplicates()\n    df = df[(df.NumOfProducts < 4) | (df.HasCrCard == 1)]\n    return df\n\ndef processing3(df):\n    df['IsSenior'] = df['Age'].apply(lambda x: 1 if x >= 60 else 0)\n    df['IsActive_by_CreditCard'] = df['HasCrCard'] * df['IsActiveMember']\n    df['Products_Per_Tenure'] =  df['Tenure'] / df['NumOfProducts']\n    df['AgeCat'] = np.round(df.Age/20).astype('int').astype('category')\n    df['Sur_Geo_Gend_Sal'] = df['Surname']+df['Geography']+df['Gender']+np.round(df.EstimatedSalary).astype('str')\n    return df\n\n\n#df_train = processing1(df_train)\n\ndf_train = processing2(df_train)\n\ndf_train = processing3(df_train)\n#df_test = processing1(df_test)\ndf_test = processing3(df_test)","metadata":{"execution":{"iopub.status.busy":"2024-01-31T06:48:53.530133Z","iopub.execute_input":"2024-01-31T06:48:53.535274Z","iopub.status.idle":"2024-01-31T06:49:10.983121Z","shell.execute_reply.started":"2024-01-31T06:48:53.535088Z","shell.execute_reply":"2024-01-31T06:49:10.981356Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Fit the AutoGluon predictor","metadata":{}},{"cell_type":"code","source":"train = TabularDataset(df_train)\ntest = TabularDataset(df_test)\n\n\nautoml = TabularPredictor(label='Exited', problem_type='binary', eval_metric='roc_auc')\nautoml.fit(train, presets='best_quality')","metadata":{"execution":{"iopub.status.busy":"2024-01-31T06:49:10.985617Z","iopub.execute_input":"2024-01-31T06:49:10.98603Z","iopub.status.idle":"2024-01-31T07:50:23.853732Z","shell.execute_reply.started":"2024-01-31T06:49:10.985982Z","shell.execute_reply":"2024-01-31T07:50:23.852319Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"No path specified. Models will be saved in: \"AutogluonModels/ag-20240131_064910\"\nPresets specified: ['best_quality']\nStack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\nDynamic stacking is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\nDetecting stacked overfitting by sub-fitting AutoGluon on the input data. That is, copies of AutoGluon will be sub-fit on subset(s) of the data. Then, the holdout validation data is used to detect stacked overfitting.\nSub-fit(s) time limit is: 3600 seconds.\nStarting holdout-based sub-fit for dynamic stacking. Context path is: AutogluonModels/ag-20240131_064910/ds_sub_fit/sub_fit_ho.\n2024-01-31 06:49:12,070\tINFO util.py:129 -- Outdated packages:\n  ipywidgets==7.7.1 found, needs ipywidgets>=8\nRun `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\nBeginning AutoGluon training ... Time limit = 900s\nAutoGluon will save models to \"AutogluonModels/ag-20240131_064910/ds_sub_fit/sub_fit_ho\"\n=================== System Info ===================\nAutoGluon Version:  1.0.0\nPython Version:     3.10.13\nOperating System:   Linux\nPlatform Machine:   x86_64\nPlatform Version:   #1 SMP Tue Dec 19 13:14:11 UTC 2023\nCPU Count:          4\nMemory Avail:       29.85 GB / 31.36 GB (95.2%)\nDisk Space Avail:   19.50 GB / 19.52 GB (99.9%)\n===================================================\nTrain Data Rows:    154662\nTrain Data Columns: 17\nLabel Column:       Exited\nProblem Type:       binary\nPreprocessing data ...\nSelected class <--> label mapping:  class 1 = 1, class 0 = 0\nUsing Feature Generators to preprocess the data ...\nFitting AutoMLPipelineFeatureGenerator...\n\tAvailable Memory:                    30583.91 MB\n\tTrain Data (Original)  Memory Usage: 54.19 MB (0.2% of available memory)\n\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n\tStage 1 Generators:\n\t\tFitting AsTypeFeatureGenerator...\n\t\t\tNote: Converting 5 features to boolean dtype as they only contain 2 unique values.\n\tStage 2 Generators:\n\t\tFitting FillNaFeatureGenerator...\n\tStage 3 Generators:\n\t\tFitting IdentityFeatureGenerator...\n\t\tFitting CategoryFeatureGenerator...\n\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n\tStage 4 Generators:\n\t\tFitting DropUniqueFeatureGenerator...\n\tStage 5 Generators:\n\t\tFitting DropDuplicatesFeatureGenerator...\n\tTypes of features in original data (raw dtype, special dtypes):\n\t\t('category', []) : 1 | ['AgeCat']\n\t\t('float', [])    : 7 | ['Age', 'Balance', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary', ...]\n\t\t('int', [])      : 5 | ['CustomerId', 'CreditScore', 'Tenure', 'NumOfProducts', 'IsSenior']\n\t\t('object', [])   : 4 | ['Surname', 'Geography', 'Gender', 'Sur_Geo_Gend_Sal']\n\tTypes of features in processed data (raw dtype, special dtypes):\n\t\t('category', [])  : 4 | ['Surname', 'Geography', 'AgeCat', 'Sur_Geo_Gend_Sal']\n\t\t('float', [])     : 4 | ['Age', 'Balance', 'EstimatedSalary', 'Products_Per_Tenure']\n\t\t('int', [])       : 4 | ['CustomerId', 'CreditScore', 'Tenure', 'NumOfProducts']\n\t\t('int', ['bool']) : 5 | ['Gender', 'HasCrCard', 'IsActiveMember', 'IsSenior', 'IsActive_by_CreditCard']\n\t1.9s = Fit runtime\n\t17 features in original data used to generate 17 features in processed data.\n\tTrain Data (Processed) Memory Usage: 11.06 MB (0.0% of available memory)\nData preprocessing and feature engineering runtime = 2.05s ...\nAutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n\tTo change this, specify the eval_metric parameter of Predictor()\nLarge model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\nUser-specified model hyperparameters to be fit:\n{\n\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n}\nAutoGluon will fit 2 stack levels (L1 to L2) ...\nFitting 110 L1 models ...\nFitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 598.48s of the 897.92s of remaining time.\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: running accelerated version on CPU\nINFO:sklearnex: sklearn.neighbors.KNeighborsClassifier.fit: running accelerated version on CPU\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: running accelerated version on CPU\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: running accelerated version on CPU\nINFO:sklearnex: sklearn.neighbors.KNeighborsClassifier.fit: running accelerated version on CPU\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: running accelerated version on CPU\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: running accelerated version on CPU\nINFO:sklearnex: sklearn.neighbors.KNeighborsClassifier.fit: running accelerated version on CPU\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: running accelerated version on CPU\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: fallback to original Scikit-learn\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: running accelerated version on CPU\nINFO:sklearnex: sklearn.neighbors.KNeighborsClassifier.fit: running accelerated version on CPU\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: running accelerated version on CPU\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: fallback to original Scikit-learn\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: running accelerated version on CPU\nINFO:sklearnex: sklearn.neighbors.KNeighborsClassifier.fit: running accelerated version on CPU\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: running accelerated version on CPU\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: fallback to original Scikit-learn\nINFO:sklearnex: sklearn.neighbors.KNeighborsClassifier.predict_proba: running accelerated version on CPU\nINFO:sklearnex: sklearn.neighbors.KNeighborsClassifier.kneighbors: running accelerated version on CPU\n\t0.5368\t = Validation score   (roc_auc)\n\t1.48s\t = Training   runtime\n\t1.51s\t = Validation runtime\nFitting model: KNeighborsDist_BAG_L1 ... Training model for up to 592.41s of the 891.85s of remaining time.\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: running accelerated version on CPU\nINFO:sklearnex: sklearn.neighbors.KNeighborsClassifier.fit: running accelerated version on CPU\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: running accelerated version on CPU\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: running accelerated version on CPU\nINFO:sklearnex: sklearn.neighbors.KNeighborsClassifier.fit: running accelerated version on CPU\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: running accelerated version on CPU\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: running accelerated version on CPU\nINFO:sklearnex: sklearn.neighbors.KNeighborsClassifier.fit: running accelerated version on CPU\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: running accelerated version on CPU\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: fallback to original Scikit-learn\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: running accelerated version on CPU\nINFO:sklearnex: sklearn.neighbors.KNeighborsClassifier.fit: running accelerated version on CPU\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: running accelerated version on CPU\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: fallback to original Scikit-learn\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: running accelerated version on CPU\nINFO:sklearnex: sklearn.neighbors.KNeighborsClassifier.fit: running accelerated version on CPU\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: running accelerated version on CPU\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: fallback to original Scikit-learn\nINFO:sklearnex: sklearn.neighbors.KNeighborsClassifier.predict_proba: running accelerated version on CPU\nINFO:sklearnex: sklearn.neighbors.KNeighborsClassifier.kneighbors: running accelerated version on CPU\n\t0.537\t = Validation score   (roc_auc)\n\t0.33s\t = Training   runtime\n\t1.46s\t = Validation runtime\nFitting model: LightGBMXT_BAG_L1 ... Training model for up to 590.47s of the 889.91s of remaining time.\n\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.28%)\n/opt/conda/lib/python3.10/site-packages/requests/__init__.py:109: RequestsDependencyWarning: urllib3 (2.1.0) or chardet (None)/charset_normalizer (3.3.2) doesn't match a supported version!\n  warnings.warn(\n\t0.8921\t = Validation score   (roc_auc)\n\t191.98s\t = Training   runtime\n\t30.75s\t = Validation runtime\nFitting model: LightGBM_BAG_L1 ... Training model for up to 384.73s of the 684.17s of remaining time.\n\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.28%)\n\t0.8894\t = Validation score   (roc_auc)\n\t72.61s\t = Training   runtime\n\t8.28s\t = Validation runtime\nFitting model: RandomForestGini_BAG_L1 ... Training model for up to 305.85s of the 605.29s of remaining time.\n\t0.8789\t = Validation score   (roc_auc)\n\t62.43s\t = Training   runtime\n\t8.07s\t = Validation runtime\nFitting model: RandomForestEntr_BAG_L1 ... Training model for up to 232.53s of the 531.97s of remaining time.\n\t0.8782\t = Validation score   (roc_auc)\n\t73.3s\t = Training   runtime\n\t8.37s\t = Validation runtime\nFitting model: CatBoost_BAG_L1 ... Training model for up to 147.77s of the 447.21s of remaining time.\n\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.29%)\n\t0.8925\t = Validation score   (roc_auc)\n\t125.64s\t = Training   runtime\n\t1.19s\t = Validation runtime\nFitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 16.52s of the 315.96s of remaining time.\n\tNot enough time to generate out-of-fold predictions for model. Estimated time required was 42.85s compared to 10s of available time.\n\tTime limit exceeded... Skipping ExtraTreesGini_BAG_L1.\nFitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 281.75s of remaining time.\n\tEnsemble Weights: {'CatBoost_BAG_L1': 0.484, 'LightGBMXT_BAG_L1': 0.323, 'LightGBM_BAG_L1': 0.161, 'RandomForestGini_BAG_L1': 0.032}\n\t0.8937\t = Validation score   (roc_auc)\n\t24.06s\t = Training   runtime\n\t0.03s\t = Validation runtime\nFitting 108 L2 models ...\nFitting model: LightGBMXT_BAG_L2 ... Training model for up to 257.63s of the 257.56s of remaining time.\n\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.37%)\n\t0.8936\t = Validation score   (roc_auc)\n\t88.67s\t = Training   runtime\n\t7.28s\t = Validation runtime\nFitting model: LightGBM_BAG_L2 ... Training model for up to 162.41s of the 162.34s of remaining time.\n\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.38%)\n\t0.891\t = Validation score   (roc_auc)\n\t64.41s\t = Training   runtime\n\t4.01s\t = Validation runtime\nFitting model: RandomForestGini_BAG_L2 ... Training model for up to 91.7s of the 91.63s of remaining time.\n\tNot enough time to generate out-of-fold predictions for model. Estimated time required was 44.93s compared to 21.25s of available time.\n\tTime limit exceeded... Skipping RandomForestGini_BAG_L2.\nFitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -7.49s of remaining time.\n\tEnsemble Weights: {'LightGBMXT_BAG_L2': 0.472, 'CatBoost_BAG_L1': 0.321, 'LightGBMXT_BAG_L1': 0.113, 'LightGBM_BAG_L2': 0.057, 'LightGBM_BAG_L1': 0.038}\n\t0.894\t = Validation score   (roc_auc)\n\t30.43s\t = Training   runtime\n\t0.03s\t = Validation runtime\nAutoGluon training complete, total runtime = 938.02s ... Best model: \"WeightedEnsemble_L3\"\nTabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240131_064910/ds_sub_fit/sub_fit_ho\")\nINFO:sklearnex: sklearn.neighbors.KNeighborsClassifier.predict_proba: running accelerated version on CPU\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: running accelerated version on CPU\nINFO:sklearnex: sklearn.neighbors.KNeighborsClassifier.predict_proba: running accelerated version on CPU\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: running accelerated version on CPU\nLeaderboard on holdout data from dynamic stacking:\n                      model  holdout_score  score_val eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n0         LightGBMXT_BAG_L2       0.892825   0.893636     roc_auc       13.855663      66.907881  616.442641                 1.317637                7.278401          88.667120            2       True          9\n1       WeightedEnsemble_L3       0.892569   0.894047     roc_auc       14.476880      70.947533  711.280644                 0.005293                0.028605          30.427361            3       True         11\n2       WeightedEnsemble_L2       0.891923   0.893727     roc_auc       10.142102      48.323526  476.727885                 0.005975                0.029268          24.062939            2       True          8\n3         LightGBMXT_BAG_L1       0.891216   0.892053     roc_auc        5.577727      30.752154  191.983870                 5.577727               30.752154         191.983870            1       True          3\n4           LightGBM_BAG_L2       0.890603   0.891007     roc_auc       13.153950      63.640526  592.186163                 0.615923                4.011046          64.410643            2       True         10\n5           CatBoost_BAG_L1       0.890425   0.892527     roc_auc        0.646430       1.187788  125.640937                 0.646430                1.187788         125.640937            1       True          7\n6           LightGBM_BAG_L1       0.888581   0.889431     roc_auc        1.227762       8.281251   72.605813                 1.227762                8.281251          72.605813            1       True          4\n7   RandomForestEntr_BAG_L1       0.879410   0.878182     roc_auc        1.951501       8.374416   73.296625                 1.951501                8.374416          73.296625            1       True          6\n8   RandomForestGini_BAG_L1       0.879032   0.878871     roc_auc        2.684209       8.073064   62.434327                 2.684209                8.073064          62.434327            1       True          5\n9     KNeighborsDist_BAG_L1       0.543562   0.537019     roc_auc        0.194922       1.455696    0.330707                 0.194922                1.455696           0.330707            1       True          2\n10    KNeighborsUnif_BAG_L1       0.541310   0.536807     roc_auc        0.255476       1.505110    1.483243                 0.255476                1.505110           1.483243            1       True          1\nStacked overfitting occurred: False.\nSpend 954 seconds for the sub-fit(s) during dynamic stacking.\nTime left for full fit of AutoGluon: 2646 seconds.\nStarting full fit now with num_stack_levels 1.\nBeginning AutoGluon training ... Time limit = 2646s\nAutoGluon will save models to \"AutogluonModels/ag-20240131_064910\"\n=================== System Info ===================\nAutoGluon Version:  1.0.0\nPython Version:     3.10.13\nOperating System:   Linux\nPlatform Machine:   x86_64\nPlatform Version:   #1 SMP Tue Dec 19 13:14:11 UTC 2023\nCPU Count:          4\nMemory Avail:       28.82 GB / 31.36 GB (91.9%)\nDisk Space Avail:   19.50 GB / 19.52 GB (99.9%)\n===================================================\nTrain Data Rows:    173995\nTrain Data Columns: 17\nLabel Column:       Exited\nProblem Type:       binary\nPreprocessing data ...\nSelected class <--> label mapping:  class 1 = 1, class 0 = 0\nUsing Feature Generators to preprocess the data ...\nFitting AutoMLPipelineFeatureGenerator...\n\tAvailable Memory:                    29561.34 MB\n\tTrain Data (Original)  Memory Usage: 60.97 MB (0.2% of available memory)\n\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n\tStage 1 Generators:\n\t\tFitting AsTypeFeatureGenerator...\n\t\t\tNote: Converting 5 features to boolean dtype as they only contain 2 unique values.\n\tStage 2 Generators:\n\t\tFitting FillNaFeatureGenerator...\n\tStage 3 Generators:\n\t\tFitting IdentityFeatureGenerator...\n\t\tFitting CategoryFeatureGenerator...\n\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n\tStage 4 Generators:\n\t\tFitting DropUniqueFeatureGenerator...\n\tStage 5 Generators:\n\t\tFitting DropDuplicatesFeatureGenerator...\n\tTypes of features in original data (raw dtype, special dtypes):\n\t\t('category', []) : 1 | ['AgeCat']\n\t\t('float', [])    : 7 | ['Age', 'Balance', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary', ...]\n\t\t('int', [])      : 5 | ['CustomerId', 'CreditScore', 'Tenure', 'NumOfProducts', 'IsSenior']\n\t\t('object', [])   : 4 | ['Surname', 'Geography', 'Gender', 'Sur_Geo_Gend_Sal']\n\tTypes of features in processed data (raw dtype, special dtypes):\n\t\t('category', [])  : 4 | ['Surname', 'Geography', 'AgeCat', 'Sur_Geo_Gend_Sal']\n\t\t('float', [])     : 4 | ['Age', 'Balance', 'EstimatedSalary', 'Products_Per_Tenure']\n\t\t('int', [])       : 4 | ['CustomerId', 'CreditScore', 'Tenure', 'NumOfProducts']\n\t\t('int', ['bool']) : 5 | ['Gender', 'HasCrCard', 'IsActiveMember', 'IsSenior', 'IsActive_by_CreditCard']\n\t1.8s = Fit runtime\n\t17 features in original data used to generate 17 features in processed data.\n\tTrain Data (Processed) Memory Usage: 12.45 MB (0.0% of available memory)\nData preprocessing and feature engineering runtime = 1.91s ...\nAutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n\tTo change this, specify the eval_metric parameter of Predictor()\nLarge model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\nUser-specified model hyperparameters to be fit:\n{\n\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n}\nAutoGluon will fit 2 stack levels (L1 to L2) ...\nFitting 110 L1 models ...\nFitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 1762.28s of the 2644.06s of remaining time.\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: running accelerated version on CPU\nINFO:sklearnex: sklearn.neighbors.KNeighborsClassifier.fit: running accelerated version on CPU\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: running accelerated version on CPU\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: running accelerated version on CPU\nINFO:sklearnex: sklearn.neighbors.KNeighborsClassifier.fit: running accelerated version on CPU\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: running accelerated version on CPU\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: running accelerated version on CPU\nINFO:sklearnex: sklearn.neighbors.KNeighborsClassifier.fit: running accelerated version on CPU\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: running accelerated version on CPU\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: fallback to original Scikit-learn\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: running accelerated version on CPU\nINFO:sklearnex: sklearn.neighbors.KNeighborsClassifier.fit: running accelerated version on CPU\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: running accelerated version on CPU\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: fallback to original Scikit-learn\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: running accelerated version on CPU\nINFO:sklearnex: sklearn.neighbors.KNeighborsClassifier.fit: running accelerated version on CPU\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: running accelerated version on CPU\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: fallback to original Scikit-learn\nINFO:sklearnex: sklearn.neighbors.KNeighborsClassifier.predict_proba: running accelerated version on CPU\nINFO:sklearnex: sklearn.neighbors.KNeighborsClassifier.kneighbors: running accelerated version on CPU\n\t0.5381\t = Validation score   (roc_auc)\n\t0.34s\t = Training   runtime\n\t1.54s\t = Validation runtime\nFitting model: KNeighborsDist_BAG_L1 ... Training model for up to 1760.3s of the 2642.07s of remaining time.\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: running accelerated version on CPU\nINFO:sklearnex: sklearn.neighbors.KNeighborsClassifier.fit: running accelerated version on CPU\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: running accelerated version on CPU\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: running accelerated version on CPU\nINFO:sklearnex: sklearn.neighbors.KNeighborsClassifier.fit: running accelerated version on CPU\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: running accelerated version on CPU\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: running accelerated version on CPU\nINFO:sklearnex: sklearn.neighbors.KNeighborsClassifier.fit: running accelerated version on CPU\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: running accelerated version on CPU\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: fallback to original Scikit-learn\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: running accelerated version on CPU\nINFO:sklearnex: sklearn.neighbors.KNeighborsClassifier.fit: running accelerated version on CPU\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: running accelerated version on CPU\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: fallback to original Scikit-learn\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: running accelerated version on CPU\nINFO:sklearnex: sklearn.neighbors.KNeighborsClassifier.fit: running accelerated version on CPU\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: running accelerated version on CPU\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: fallback to original Scikit-learn\nINFO:sklearnex: sklearn.neighbors.KNeighborsClassifier.predict_proba: running accelerated version on CPU\nINFO:sklearnex: sklearn.neighbors.KNeighborsClassifier.kneighbors: running accelerated version on CPU\n\t0.5389\t = Validation score   (roc_auc)\n\t0.34s\t = Training   runtime\n\t1.54s\t = Validation runtime\nFitting model: LightGBMXT_BAG_L1 ... Training model for up to 1758.29s of the 2640.07s of remaining time.\n\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.32%)\n\t0.8921\t = Validation score   (roc_auc)\n\t235.79s\t = Training   runtime\n\t39.58s\t = Validation runtime\nFitting model: LightGBM_BAG_L1 ... Training model for up to 1513.82s of the 2395.59s of remaining time.\n\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.32%)\n\t0.8895\t = Validation score   (roc_auc)\n\t83.27s\t = Training   runtime\n\t9.15s\t = Validation runtime\nFitting model: RandomForestGini_BAG_L1 ... Training model for up to 1414.64s of the 2296.42s of remaining time.\n\t0.8797\t = Validation score   (roc_auc)\n\t67.22s\t = Training   runtime\n\t8.47s\t = Validation runtime\nFitting model: RandomForestEntr_BAG_L1 ... Training model for up to 1336.05s of the 2217.83s of remaining time.\n\t0.8794\t = Validation score   (roc_auc)\n\t82.57s\t = Training   runtime\n\t8.83s\t = Validation runtime\nFitting model: CatBoost_BAG_L1 ... Training model for up to 1241.65s of the 2123.43s of remaining time.\n\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.33%)\n\t0.8956\t = Validation score   (roc_auc)\n\t1003.93s\t = Training   runtime\n\t3.0s\t = Validation runtime\nFitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 232.14s of the 1113.91s of remaining time.\n\t0.8817\t = Validation score   (roc_auc)\n\t43.71s\t = Training   runtime\n\t8.01s\t = Validation runtime\nFitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 177.03s of the 1058.8s of remaining time.\n\t0.8818\t = Validation score   (roc_auc)\n\t34.0s\t = Training   runtime\n\t8.41s\t = Validation runtime\nFitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 131.43s of the 1013.21s of remaining time.\n\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.52%)\n\t0.8891\t = Validation score   (roc_auc)\n\t106.38s\t = Training   runtime\n\t10.33s\t = Validation runtime\nFitting model: XGBoost_BAG_L1 ... Training model for up to 18.22s of the 900.0s of remaining time.\n\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.45%)\n\t0.8847\t = Validation score   (roc_auc)\n\t22.63s\t = Training   runtime\n\t1.42s\t = Validation runtime\nFitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 870.42s of remaining time.\n\tEnsemble Weights: {'CatBoost_BAG_L1': 0.8, 'LightGBM_BAG_L1': 0.12, 'LightGBMXT_BAG_L1': 0.04, 'NeuralNetFastAI_BAG_L1': 0.04}\n\t0.8959\t = Validation score   (roc_auc)\n\t41.61s\t = Training   runtime\n\t0.03s\t = Validation runtime\nFitting 108 L2 models ...\nFitting model: LightGBMXT_BAG_L2 ... Training model for up to 828.74s of the 828.64s of remaining time.\n\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.49%)\n\t0.8951\t = Validation score   (roc_auc)\n\t142.96s\t = Training   runtime\n\t9.97s\t = Validation runtime\nFitting model: LightGBM_BAG_L2 ... Training model for up to 679.02s of the 678.92s of remaining time.\n\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.49%)\n\t0.8928\t = Validation score   (roc_auc)\n\t86.31s\t = Training   runtime\n\t5.5s\t = Validation runtime\nFitting model: RandomForestGini_BAG_L2 ... Training model for up to 586.06s of the 585.96s of remaining time.\n\t0.8924\t = Validation score   (roc_auc)\n\t172.7s\t = Training   runtime\n\t10.43s\t = Validation runtime\nFitting model: RandomForestEntr_BAG_L2 ... Training model for up to 399.49s of the 399.39s of remaining time.\n\t0.8942\t = Validation score   (roc_auc)\n\t190.09s\t = Training   runtime\n\t9.82s\t = Validation runtime\nFitting model: CatBoost_BAG_L2 ... Training model for up to 196.44s of the 196.34s of remaining time.\n\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=0.51%)\n\t0.8966\t = Validation score   (roc_auc)\n\t163.83s\t = Training   runtime\n\t2.11s\t = Validation runtime\nFitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 26.79s of the 26.69s of remaining time.\n\tNot enough time to generate out-of-fold predictions for model. Estimated time required was 42.9s compared to 10s of available time.\n\tTime limit exceeded... Skipping ExtraTreesGini_BAG_L2.\nFitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -12.08s of remaining time.\n\tEnsemble Weights: {'CatBoost_BAG_L2': 0.556, 'RandomForestEntr_BAG_L2': 0.222, 'CatBoost_BAG_L1': 0.111, 'RandomForestGini_BAG_L2': 0.111}\n\t0.8973\t = Validation score   (roc_auc)\n\t60.31s\t = Training   runtime\n\t0.03s\t = Validation runtime\nAutoGluon training complete, total runtime = 2718.5s ... Best model: \"WeightedEnsemble_L3\"\nTabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240131_064910\")\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"<autogluon.tabular.predictor.predictor.TabularPredictor at 0x7dfc0d6334c0>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Explore the leaderboard","metadata":{}},{"cell_type":"code","source":"automl.leaderboard()\n","metadata":{"execution":{"iopub.status.busy":"2024-01-31T07:50:23.855761Z","iopub.execute_input":"2024-01-31T07:50:23.857711Z","iopub.status.idle":"2024-01-31T07:50:23.89462Z","shell.execute_reply.started":"2024-01-31T07:50:23.857643Z","shell.execute_reply":"2024-01-31T07:50:23.893459Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                      model  score_val eval_metric  pred_time_val  \\\n0       WeightedEnsemble_L3   0.897283     roc_auc     122.673525   \n1           CatBoost_BAG_L2   0.896596     roc_auc     102.386087   \n2       WeightedEnsemble_L2   0.895909     roc_auc      62.095538   \n3           CatBoost_BAG_L1   0.895646     roc_auc       2.997290   \n4         LightGBMXT_BAG_L2   0.895085     roc_auc     110.244089   \n5   RandomForestEntr_BAG_L2   0.894231     roc_auc     110.091136   \n6           LightGBM_BAG_L2   0.892767     roc_auc     105.775692   \n7   RandomForestGini_BAG_L2   0.892413     roc_auc     110.705577   \n8         LightGBMXT_BAG_L1   0.892110     roc_auc      39.581874   \n9           LightGBM_BAG_L1   0.889451     roc_auc       9.149957   \n10   NeuralNetFastAI_BAG_L1   0.889106     roc_auc      10.332548   \n11           XGBoost_BAG_L1   0.884713     roc_auc       1.423449   \n12    ExtraTreesEntr_BAG_L1   0.881760     roc_auc       8.409935   \n13    ExtraTreesGini_BAG_L1   0.881743     roc_auc       8.008250   \n14  RandomForestGini_BAG_L1   0.879713     roc_auc       8.467657   \n15  RandomForestEntr_BAG_L1   0.879448     roc_auc       8.827336   \n16    KNeighborsDist_BAG_L1   0.538932     roc_auc       1.535996   \n17    KNeighborsUnif_BAG_L1   0.538113     roc_auc       1.536894   \n\n       fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n0   2267.090975                0.033096          60.307057            3   \n1   1844.000767                2.114902         163.827751            2   \n2   1470.974447                0.033869          41.606848            2   \n3   1003.926952                2.997290        1003.926952            1   \n4   1823.134831                9.972903         142.961816            2   \n5   1870.259607                9.819950         190.086591            2   \n6   1766.487950                5.504506          86.314935            2   \n7   1852.869575               10.434392         172.696560            2   \n8    235.790665               39.581874         235.790665            1   \n9     83.271108                9.149957          83.271108            1   \n10   106.378874               10.332548         106.378874            1   \n11    22.628191                1.423449          22.628191            1   \n12    34.001423                8.409935          34.001423            1   \n13    43.706676                8.008250          43.706676            1   \n14    67.218348                8.467657          67.218348            1   \n15    82.572150                8.827336          82.572150            1   \n16     0.339828                1.535996           0.339828            1   \n17     0.338801                1.536894           0.338801            1   \n\n    can_infer  fit_order  \n0        True         18  \n1        True         17  \n2        True         12  \n3        True          7  \n4        True         13  \n5        True         16  \n6        True         14  \n7        True         15  \n8        True          3  \n9        True          4  \n10       True         10  \n11       True         11  \n12       True          9  \n13       True          8  \n14       True          5  \n15       True          6  \n16       True          2  \n17       True          1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>score_val</th>\n      <th>eval_metric</th>\n      <th>pred_time_val</th>\n      <th>fit_time</th>\n      <th>pred_time_val_marginal</th>\n      <th>fit_time_marginal</th>\n      <th>stack_level</th>\n      <th>can_infer</th>\n      <th>fit_order</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>WeightedEnsemble_L3</td>\n      <td>0.897283</td>\n      <td>roc_auc</td>\n      <td>122.673525</td>\n      <td>2267.090975</td>\n      <td>0.033096</td>\n      <td>60.307057</td>\n      <td>3</td>\n      <td>True</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CatBoost_BAG_L2</td>\n      <td>0.896596</td>\n      <td>roc_auc</td>\n      <td>102.386087</td>\n      <td>1844.000767</td>\n      <td>2.114902</td>\n      <td>163.827751</td>\n      <td>2</td>\n      <td>True</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>WeightedEnsemble_L2</td>\n      <td>0.895909</td>\n      <td>roc_auc</td>\n      <td>62.095538</td>\n      <td>1470.974447</td>\n      <td>0.033869</td>\n      <td>41.606848</td>\n      <td>2</td>\n      <td>True</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CatBoost_BAG_L1</td>\n      <td>0.895646</td>\n      <td>roc_auc</td>\n      <td>2.997290</td>\n      <td>1003.926952</td>\n      <td>2.997290</td>\n      <td>1003.926952</td>\n      <td>1</td>\n      <td>True</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>LightGBMXT_BAG_L2</td>\n      <td>0.895085</td>\n      <td>roc_auc</td>\n      <td>110.244089</td>\n      <td>1823.134831</td>\n      <td>9.972903</td>\n      <td>142.961816</td>\n      <td>2</td>\n      <td>True</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>RandomForestEntr_BAG_L2</td>\n      <td>0.894231</td>\n      <td>roc_auc</td>\n      <td>110.091136</td>\n      <td>1870.259607</td>\n      <td>9.819950</td>\n      <td>190.086591</td>\n      <td>2</td>\n      <td>True</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>LightGBM_BAG_L2</td>\n      <td>0.892767</td>\n      <td>roc_auc</td>\n      <td>105.775692</td>\n      <td>1766.487950</td>\n      <td>5.504506</td>\n      <td>86.314935</td>\n      <td>2</td>\n      <td>True</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>RandomForestGini_BAG_L2</td>\n      <td>0.892413</td>\n      <td>roc_auc</td>\n      <td>110.705577</td>\n      <td>1852.869575</td>\n      <td>10.434392</td>\n      <td>172.696560</td>\n      <td>2</td>\n      <td>True</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>LightGBMXT_BAG_L1</td>\n      <td>0.892110</td>\n      <td>roc_auc</td>\n      <td>39.581874</td>\n      <td>235.790665</td>\n      <td>39.581874</td>\n      <td>235.790665</td>\n      <td>1</td>\n      <td>True</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>LightGBM_BAG_L1</td>\n      <td>0.889451</td>\n      <td>roc_auc</td>\n      <td>9.149957</td>\n      <td>83.271108</td>\n      <td>9.149957</td>\n      <td>83.271108</td>\n      <td>1</td>\n      <td>True</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>NeuralNetFastAI_BAG_L1</td>\n      <td>0.889106</td>\n      <td>roc_auc</td>\n      <td>10.332548</td>\n      <td>106.378874</td>\n      <td>10.332548</td>\n      <td>106.378874</td>\n      <td>1</td>\n      <td>True</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>XGBoost_BAG_L1</td>\n      <td>0.884713</td>\n      <td>roc_auc</td>\n      <td>1.423449</td>\n      <td>22.628191</td>\n      <td>1.423449</td>\n      <td>22.628191</td>\n      <td>1</td>\n      <td>True</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>ExtraTreesEntr_BAG_L1</td>\n      <td>0.881760</td>\n      <td>roc_auc</td>\n      <td>8.409935</td>\n      <td>34.001423</td>\n      <td>8.409935</td>\n      <td>34.001423</td>\n      <td>1</td>\n      <td>True</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>ExtraTreesGini_BAG_L1</td>\n      <td>0.881743</td>\n      <td>roc_auc</td>\n      <td>8.008250</td>\n      <td>43.706676</td>\n      <td>8.008250</td>\n      <td>43.706676</td>\n      <td>1</td>\n      <td>True</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>RandomForestGini_BAG_L1</td>\n      <td>0.879713</td>\n      <td>roc_auc</td>\n      <td>8.467657</td>\n      <td>67.218348</td>\n      <td>8.467657</td>\n      <td>67.218348</td>\n      <td>1</td>\n      <td>True</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>RandomForestEntr_BAG_L1</td>\n      <td>0.879448</td>\n      <td>roc_auc</td>\n      <td>8.827336</td>\n      <td>82.572150</td>\n      <td>8.827336</td>\n      <td>82.572150</td>\n      <td>1</td>\n      <td>True</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>KNeighborsDist_BAG_L1</td>\n      <td>0.538932</td>\n      <td>roc_auc</td>\n      <td>1.535996</td>\n      <td>0.339828</td>\n      <td>1.535996</td>\n      <td>0.339828</td>\n      <td>1</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>KNeighborsUnif_BAG_L1</td>\n      <td>0.538113</td>\n      <td>roc_auc</td>\n      <td>1.536894</td>\n      <td>0.338801</td>\n      <td>1.536894</td>\n      <td>0.338801</td>\n      <td>1</td>\n      <td>True</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Make a 'pure' submission file","metadata":{}},{"cell_type":"code","source":"prediction = automl.predict_proba(test)\n\n\ndata_submit = pd.read_csv('/kaggle/input/playground-series-s4e1/sample_submission.csv')\ndata_submit.Exited = prediction[1]\ndata_submit[['id', 'Exited']].to_csv('ag_processing.csv', index=False)\n\n\n!head ag_processing.csv","metadata":{"_uuid":"7a53e1e2-e694-4b8f-8430-e442fadedb50","_cell_guid":"38fa7a34-bd40-4b6b-975f-4385ed5a3122","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-31T07:50:23.897053Z","iopub.execute_input":"2024-01-31T07:50:23.898062Z","iopub.status.idle":"2024-01-31T07:52:20.404246Z","shell.execute_reply.started":"2024-01-31T07:50:23.898022Z","shell.execute_reply":"2024-01-31T07:52:20.398594Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"INFO:sklearnex: sklearn.neighbors.KNeighborsClassifier.predict_proba: running accelerated version on CPU\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: running accelerated version on CPU\nINFO:sklearnex: sklearn.neighbors.KNeighborsClassifier.predict_proba: running accelerated version on CPU\nINFO:sklearnex: sklearn.utils.validation._assert_all_finite: running accelerated version on CPU\n","output_type":"stream"},{"name":"stdout","text":"id,Exited\n165034,0.014006898738443851\n165035,0.8474394679069519\n165036,0.012188786640763283\n165037,0.21654006838798523\n165038,0.3771299123764038\n165039,0.0474398210644722\n165040,0.01613999903202057\n165041,0.06275671720504761\n165042,0.6438615322113037\n","output_type":"stream"}]},{"cell_type":"code","source":"df_ext1 = pd.read_csv('/kaggle/input/playgrounds4e01-baseline-v2/Submission_V2.csv') \n\n# 0.89651\n\n\ndata_submit.Exited = 0.15 * data_submit.Exited + 0.85 * df_ext1.Exited\ndata_submit[['id', 'Exited']].to_csv('ensemble.csv', index=False)\n\n\n\n!head ensemble.csv","metadata":{"execution":{"iopub.status.busy":"2024-01-31T07:52:20.414126Z","iopub.execute_input":"2024-01-31T07:52:20.415845Z","iopub.status.idle":"2024-01-31T07:52:22.700853Z","shell.execute_reply.started":"2024-01-31T07:52:20.415786Z","shell.execute_reply":"2024-01-31T07:52:22.698719Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"id,Exited\n165034,0.013495645096307192\n165035,0.8311415965530612\n165036,0.014482119205234933\n165037,0.19539194467648313\n165038,0.41019538211693723\n165039,0.05249883677021676\n165040,0.020357830593185786\n165041,0.08376073464967672\n165042,0.636160039999441\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}